
\begin{table}[t!]
   \centering
   \begin{tabular}{cl}
   {\bf Notation} & {\bf Description}\\\hline
   $\mathcal{V}$ & Set of video streams\\
   $v$ & A video stream ($v \in \mathcal{V}$)\\\hline
   $T$ & A retraining window with duration $\lVert T \rVert$ \\\hline
   %$t$ & A point in time within a retraining window\\\hline
   $\Gamma$ & Set of all retraining configurations\\
   $\gamma$ & A retraining configuration ($\gamma \in \Gamma$)\\\hline
   $\Lambda$ & Set of all inference configurations\\
   $\lambda$ & An inference configuration ($\lambda \in \Lambda$)\\\hline
   $\mathcal{G}$ & Total number of GPUs\\
   $\delta$ & The unit for GPU resource allocation \\\hline
   %$\Theta$ & The set of all possible GPU allocations  \\
   %      & $\Theta = \{0, 1, ..., \frac{\mathcal{G}}{\delta}\}$\\
   %$\mathcal{R}$ & The number of GPU resource unit $\delta$\\ 
   %         & allocated for retraining ($\mathcal{R} \in \Theta$)\\
   %$\mathcal{I}$ & The number of GPU resource unit $\delta$\\ 
   %         & allocated for inference ($\mathcal{I} \in \Theta$)\\\hline
   %$M_{v}^t$ & Set of all DNN instances for video $v$ at window $t$\\
   %$m_{v\gamma}^t$ & A DNN instance based on $\gamma$ for video $v$ at $t$\\
   %$\hat{m}_{v\gamma}^t$ & A \emph{retrained} DNN instance based on $\gamma$ for $v$ at $t$\\\hline
   %$C^R(v, t, \gamma)$ & Retraining cost using $v$ and $\gamma$ at window $t$ \\
   %$C^I(v, t, \gamma, \lambda)$ & Inference cost using $v$, $\gamma$, $\lambda$ at window $t$ \\
   $A_T(v, \gamma, \lambda, \mathcal{R}, \mathcal{I} )$ & Inference accuracy for video $v$ for\\%at retraining \\
                                       %& window $T$ 
                                       &given configurations and allocations\\% given retraining configuration $\gamma$ \\
                                       %& inference configuration $\lambda$, $\mathcal{R}\delta$ GPUs for\\
                                       %& retraining, and $\mathcal{I}\delta$ GPUs for inference \\
   $C_T(v, \gamma, \lambda)$ & Compute cost in GPU-time for video $v$ for\\%at retraining \\
                                       %& window $T$ for 
                                       &given configurations and allocations\\\hline%, given retraining configuration $\gamma$ \\
                                       %& and inference configuration $\lambda$ \\\hline
   %$r_{vt\gamma g}$ & A binary variable indicates the system retrains \\
   %& a DNN based on $\gamma$ for video $v$ at $t$ on GPU $g$\\\hline
   $\phi_{v\gamma\lambda\mathcal{R}\mathcal{I}}$ & A set of binary variables ($\phi_{v\gamma\lambda\mathcal{R}\mathcal{I}}\in\{0,1\}$). \\
   & $\phi_{v\gamma\lambda\mathcal{R}\mathcal{I}} = 1$ iff we use retraining config $\gamma$, \\
   %& configuration $\gamma$, 
   &inference config $\lambda$, $\mathcal{R}\delta$ GPUs for retraining,\\
   & $\mathcal{I}\delta$ GPUs for inference for video $v$\\\hline
   \end{tabular}
   \caption{\label{tab:notations}Notations used in {\name}'s description.}
   \end{table}

\subsection{Formulation of joint inference and retraining}
\label{subsec:formulation}

The problem of joint inference and retraining aims to maximize overall inference accuracy for all video streams $\mathcal{V}$ in a retraining window ${T}$ with duration $\lVert T \rVert$. 
All work must be done in $\mathcal{G}$ GPUs.
Thus, the total compute capability is $\mathcal{G}\lVert T \rVert$ GPU-time. Without loss of generality, let $\delta$ be the smallest granularity of GPU allocation.  %(e.g., if $\delta = 1\%$ of GPU, $150\delta =$ 1.5 GPU). Let $\Theta$ be the set of all possible GPU allocations $\Theta = \{0, 1, ..., \frac{\mathcal{G}}{\delta}\}$.
Each video $v \in V$ has a set of \emph{retraining} configurations $\Gamma$
and a set of \emph{inference} configurations $\Lambda$ (\S\ref{subsec:profiles}).
Table \ref{tab:notations} lists the notations. 


\noindent\textbf{Decisions.} For each video $v\in\mathcal{V}$ in a window $T$, we decide: (1) the retraining configuration $\gamma\in\Gamma$ ($\gamma = \emptyset$ means no retraining); (2) the inference configuration $\lambda\in\Lambda$; and (3) how many GPUs (in multiples of $\delta$) % (in terms of GPU resource units $\delta$)
to allocate for retraining ($\mathcal{R}$) %\in\Theta$) 
and inference ($\mathcal{I}$). %\in\Theta$). 
We use binary variables $\phi_{v\gamma\lambda\mathcal{R}\mathcal{I}}\in\{0,1\}$ to denote these decisions (see Table \ref{tab:notations} for the definition). 
These decisions require $C_T(v, \gamma, \lambda)$ GPU-time and yields overall accuracy of $A_T(v, \gamma, \lambda, \mathcal{R}, \mathcal{I})$. $A_T(v, \gamma, \lambda, \mathcal{R}, \mathcal{I})$ is averaged across the window $T$ (\S\ref{subsec:motivation-sched-example}), and the above decisions determine the inference accuracy at {\em each point in time}.
%Specifically, let $a_t(v, \gamma, \lambda, \mathcal{R}, \mathcal{I})$ be the inference accuracy for video $v$ at a point in time $t$, % given retraining configuration $\gamma$, inference configuration $\lambda$, $\mathcal{R}\delta$ GPUs for retraining, and $\mathcal{I}\delta$ GPUs for inference, we have:
%\[
%\ A_T(v, \gamma, \lambda, \mathcal{R}, \mathcal{I}) = 
%\frac{1}{\lVert T \rVert} \int_{t=0}^{\lVert T \rVert} a_t(v, \gamma, \lambda, \mathcal{R}, \mathcal{I})\ dt
%\]


%At each retraining window $t \in \mathcal{T}$, the system maintains a set of DNN instances $M_{v}^t$ for video $v$, where each $m_{v\gamma}^t \in M_{v}^t$ denotes a DNN instance that is trained based on configuration $\gamma$. Each DNN $m_{v\gamma}^0 \in M_{v}^0$ is pretrained with offline video data. 
%The system can optionally retrain $m_{v\gamma}^t$ into $\hat{m}_{v\gamma}^t$ with training configuration $\gamma$ and the video data of $v$ at $t$, and the retraining cost is $C^R(v, t, \gamma)$.

%The system must pick a DNN $m_{v\gamma}^t$ or $\hat{m}_{v\gamma}^t$ and an inference configuration $\lambda \in \Lambda$ to run inference for video $v$ at $t$.
%The inference cost of such a decision is $C^I(v, t, \gamma, \lambda$), and the inference accuracy is $A(v, t, m, \lambda)$ where $m$ is the chosen DNN. 
%We use binary variables $r_{vt\gamma g}$ and $i_{vt\gamma \lambda g}$ to indicate the decisions made by the system (see Table \ref{tab:notations} for their definitions).

\noindent\textbf{Optimization.} Maximize the inference accuracy averaged across all videos in a retraining window within the GPU limit. 

{\small
\vspace{-12pt}
\begin{equation}
    \begin{aligned}
    %\footnotesize
       & \underset{\phi_{v\gamma\lambda\mathcal{R}\mathcal{I}}}{\arg\max}
         \frac{1}{\lVert \mathcal{V} \rVert}
         \sum_{\substack{\forall v\in\mathcal{V}, 
                        \forall \gamma\in\Gamma,
                        \forall \lambda\in\Lambda,\\
                        \forall \mathcal{R}, \forall \mathcal{I} \in \{0, 1, ..., \frac{\mathcal{G}}{\delta}\} %\in \Theta,
                        %\forall \mathcal{I} \in \Theta
                        }}
          \phi_{v\gamma\lambda\mathcal{R}\mathcal{I}} \cdot
          A_T(v, \gamma, \lambda, \mathcal{R}, \mathcal{I})\\
       & \text{subject to}\\
       & 1. \sum_{\substack{\forall v\in\mathcal{V}, 
                        \forall \gamma\in\Gamma,
                        \forall \lambda\in\Lambda,\\
                        \forall \mathcal{R}, \forall \mathcal{I}}}
                        \phi_{v\gamma\lambda\mathcal{R}\mathcal{I}} \cdot
                        C_T(v, \gamma, \lambda)
                        \leq \mathcal{G}\lVert T \rVert \\
      & 2. \sum_{\substack{\forall v\in\mathcal{V},
                        \forall \gamma\in\Gamma,
                        \forall \lambda\in\Lambda,\\
                        \forall \mathcal{R}, \forall \mathcal{I}}}
                           \phi_{v\gamma\lambda\mathcal{R}\mathcal{I}} \cdot
                           (\mathcal{R} + \mathcal{I})
                        \leq \frac{\mathcal{G}}{\delta} \\
      & 3. \sum_{\substack{\forall \gamma\in\Gamma, 
                           \forall \lambda\in\Lambda,\\ 
                           \forall \mathcal{R}, %\in \Theta,
                           \forall \mathcal{I}}} %\in \Theta}}
           \phi_{v\gamma\lambda\mathcal{R}\mathcal{I}} \leq 1, 
           \forall v\in\mathcal{V}
    \end{aligned}
    \label{eqn:optimization}
\end{equation}
}%

The first constraint ensures that the GPU allocation does not exceed the available GPU-time $\mathcal{G}\lVert T \rVert$ in the retraining window. The second constraint limits the {\em instantaneous}  allocation (in multiples of $\delta$) to never exceed the available GPUs. 
%The third constraint ensures that the system can only pick at most one retraining configuration/allocation and one inference configuration/allocation for each video $v$.
The third constraint ensures that at most one configuration is picked for retraining and inference each for a video $v$.
