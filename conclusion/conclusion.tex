\chapter{Conclusion}
\label{ch_conclusion}

In this thesis, we explored the use of scheduling techniques to improve resource efficiency of machine learning workloads and bridge the compute supply-demand gap.

At the ML application layer, we targeted a specific machine learning workload - continuous learning in resource constrained settings - and developed Ekya to balance resource allocation between inference and re-training. In doing so, we discovered that selecting optimal configurations for retraining and identifying most promising tasks for allocating GPU cycles can yield upto $4\times$ improvements in GPU efficiency.

At the cluster management layer, we found that the traditional resource-demand based scheduling model where users specify exact amount of resources needed for their jobs results in inefficient use of resources. Instead, we built Cilantro to automatically produce resource allocations based on a job's performance and the user's objective. A key component of Cilantro is the use online learning, which generates progressively accurate models for a job's performance for a given resource allocation. As a result, Cilantro improves efficiency when sharing resources in two important settings - multi-tenant clusters and microservices serving a common application. 

Finally, at the the cluster orchestration layer, we discovered that ML applications are highly sensitive to the exact placement and scheduling of their tasks. ESCHER grants flexibility to these applications to exercise precise scheduling control over their tasks, without requiring tedious and brittle changes to the underlying cluster manager.

In building these systems, we observed some common trends that we highlight as lessons learnt below. We also discuss some future directions for bridging the compute supply-demand gap.

\section{Lessons Learnt}

\subsubsection{Application-awareness drives efficiency}
The growing gap in compute supply and demand necessitates improving efficiency the entire stack from hardware to software. A recurring theme in our findings is that significant efficiency gains are dependent upon vertical integration of this stack, where application-specific knowledge and signals can help optimize the usage of lower layers of the stack.

For instance, we started work on Ekya with the objective of building an application-agnostic scheduler that balances GPU cycles between training and inference, but the interdependence between jobs (i.e., the training job improves the accuracy of the inference job) required the use of signals from the thief scheduler to identify the most promising tasks for allocating GPU cycles. Similarly, Cilantro uses user-defined utility signals instead of simpler utilization based metrics to find the optimal resource allocation for a job. Finally, ESCHER is centered around the fact that applications are highly sensitive to the exact placement and scheduling of their tasks. Achieving efficiency in these settings required us to utilize information from the application to make better scheduling decisions.

\subsubsection{Good abstractions balance flexibility and complexity}
Resource management systems must strike a balance between flexibility and complexity. On one hand, flexibility is critical to support a wide range of applications and use cases. On the other hand, increasing flexibility can often increase complexity, which can make the system difficult to use and maintain. In such situations, we found it critical to design new abstractions that not only enable flexibility for applications, but do so without increasing complexity. 

ESCHER is an example of increasing flexibility while minimizing complexity through the use of a novel primitive - ephemeral resources. Ephemeral resources are a simple abstraction that allows applications to express their scheduling requirements without requiring changes to the underlying cluster manager, effectively reducing the complexity of adding new policies to existing cluster managers. Similarly, the utility specification interface in Cilantro allows applications to signal their performance to the scheduler without the use of complex APIs. 

\section{Future Work}

% \subsubsection{Improving Resource Availability}
To bridge the compute supply-demand gap, this thesis has primarily focused on easing resource demand by improving the efficiency of machine learning workloads. However, there is extensive work to be done on the supply side, particularly in the context of resource availability.

Compute resources today are fragmented across silos such as clouds and on-prem clusters, making them challenging to access and utilize efficiently. For instance, consider a user with an on-premise cluster and access to multiple clouds. Getting access to a Nvidia A100 GPU for this user entails first checking availability on their on-premise cluster. If a GPU is not available on-premise, they must check availability across different clouds and regions in each cloud. Exploiting availability becomes even more important when using spot instances because these resources may be reclaimed at any time and must be replaced with available spot instances from other clouds and regions.
% Worse yet, they must also check individual geographic regions, making the search space exponentially large and challenging to manually navigate.

We have been working towards this goal of enhancing resource availability by pursuing the Sky\cite{skyhotos} vision. We have built SkyPilot\cite{skypilot}, an intercloud broker that allows users to access compute resources across clouds and on-premise clusters through a single interface. SkyPilot automatically discovers available resources across clouds and on-premise clusters and automatically replaces resources that are reclaimed with available resources that meet the user's requirements. In effect, this allows users to access compute resources as if they were accessing a single large pool resources instead of multiple fragmented silos.

There is still much work to be done in this space. For instance, having a global map of resource availability across clouds will allow tools like SkyPilot to make better decisions about where to place jobs. However, constructing such a map is challenging because clouds do not expose their availability information. Crowdsourcing this information by collecting availability information from users can be a potential solution, but requires addressing errors in the data and privacy concerns. 

Another approach to improving supply is by sharing idle resources across users. Building systems and primitives for sharing resources across users would require not only providing isolation and performance guarantees (which have been extensively studied), but also designing incentive mechanisms to encourage users to share their resources with others who are not in their trust network.

To conclude, we believe that bridging the compute supply-demand gap is critical to the success of machine learning. It will require a combination of easing resource demand by improving efficiency and increasing resource supply through hardware advancements and availability improvements. We hope that the work in this thesis will serve as a stepping stone towards this goal.

% Finally, the heterogeneity of hardware and software across different environments presents opportunities for improving efficiency through 


% \subsubsection{Fine-grained GPU Sharing}
% GPUs are critical for accelerating machine learning workloads, but are difficult to share due to the high cost of context switching and moving data in and out of the GPU. As a result, GPUs are often statically allocated to jobs, which can lead to low utilization.  Sharing GPUs, both spatially (i.e., run multiple tasks on the same GPU in parallel) and temporally (i.e., time-slice a GPU between multiple tasks, running one task at a time), can improve utilization, but are often coarse-grained and do not allow sharing at the granularity of individual tasks. Just like how CPU sharing has specific primitives (i.e., threads), we believe that GPU sharing will also require new abstractions to support finer-grained sharing. 


% \subsubsection{Expressing policies with LLMs}
