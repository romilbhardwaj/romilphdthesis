

This concludes the description of our policies.
We wish to reiterate that Cilantro can handle any welfare or demand based policy in the multi-tenant
setting and any end-to-end performance criterion in the microservices setting.
Our only requirement is that each job's (microservice) performance be
(at least approximately) non-decreasing in the amount
of resources allocated.

\section{Discussion \& Limitations}
\label{sec:cilantro_discussion}
% This section should highlight key features of cilantro and limitation


\textbf{Cilantro limitations:}
One limitation of Cilantro is that it
does not support online learning versions of market-based resource allocation
policies in the multi-tenant setting~\citep{zahedi2018amdahl,lai2005tycoon,varian1973equity}.
Before we proceed we wish to describe fallback options for Cilantro when job feedback is not
available.


\textbf{When job feedback is unavailable.}
In many settings, application metrics are often not available. In such cases,
% If the Cilantro client has no visibility into the application metrics,
we provide built-in fallback
that can use surrogate metrics from the Kubernetes API, such as CPU utilization, to report job
performance.
In such cases, a user should specify how these surrogates are tied to their utility
and/or demand.
If this is also not possible, we allow the user to directly submit an estimate for their resource
demand via the client which will then be fed to the policy when determining allocations.
In such cases, we assume that utility increases linearly up to the demand when computing
allocations.
We evaluate this fallback option in \S\ref{sec:microbenchmarks}.
Finally, if accurate profiled information is available for a job,
this can also be directly submitted, which will be directly used instead of confidence bounds.


We wish to emphasise the generality of Cilantro.
First, in the multi-tenant setting,
the social and egalitarian welfare belong to a more general class of
welfare-based criterion, where we wish to maximize some welfare function
$W = W(\utilii{1},\dots,\utilii{n})$,
which depends on each user's utilities $\utilii{1},\dots,\utilii{n}$.
% and choose an allocation which maximizes $W$.
% The welfare function is non-decreasing in the utilities.
In such cases, \cilantro's OFU-adapted online learning policy will simply choose an
allocation on round $r$ via, $\alloc^{(r)}= \argmax W(\utilhatii{1},\dots,\utilhatii{n})$,
where
$\utilhatj = \utilpj(\payoffhatj(\allocj, \volhatj))$,
and $\payoffhatj, \volhatj$ are upper confidence bounds on the performance and load.
Similarly,
for any demand-based criterion, 
we may compute a recommended demand via~\eqref{eqn:ofudemand} by following OFU.
We can then invoke any
demand-based policy using these recommended demands to obtain the allocation.

It is also worth noting that the shape of the utility as a function of performance need not
be limited to those shown in Fig.~\ref{fig:utilityillus}; any increasing function would
suffice.
The clipping of the utility at the SLO/demand is also not required for welfare-based policies.
However, this clipping is required for demand-based policies which usually assume that there is
no additional utility for allocations more than the demand. \rbcomment{Clarify that this uses the inverse of resource-performance mapping}

Finally, in the microservices setting, we may optimize for any end-to-end performance criteria
by choosing an allocation which maximizes a UCB as given
in~\eqref{eqn:ofuappperf}.
% If we had a complex criterion $\payoff$, which depended on 
% 
In all the above cases, we require that the performance of a job or application be
(at least approximately) non-decreasing in the amount of resources allocated and 
(at least approximately) non-increasing in the load.
From a systems perspective, we require that we can collect
raw metrics from an application to compute the instantaneous (noisy) value for the performance. 

% \textbf{How are utilities specified?} Utilities in Cilantro are specified in the Cilantro client sidecar that runs with the application. Developers can specify any non-decreasing function to map their performance metrics to a utility value. As we demonstrate in \S\ref{sec:baselines}, online-learned policies are strategy-proof, so misrepresenting utilities in the cilantro client does not benefit the application.

\textbf{When job feedback is unavailable.}
In many settings, application metrics are often not available. In such cases,
% If the Cilantro client has no visibility into the application metrics,
we provide built-in fallback
that can use surrogate metrics from the Kubernetes API, such as CPU utilization, to report job
performance.
In such cases, a user should specify how these surrogates are tied to their utility
and/or demand.
If this is also not possible, we allow the user to directly submit an estimate for their resource
demand via the client which will then be fed to the policy when determining allocations.
In such cases, we assume that utility increases linearly up to the demand when computing
allocations.
We evaluate this fallback option in \S\ref{sec:microbenchmarks}.
Finally, if accurate profiled information is available for a job,
this can also be directly submitted, which will be directly used instead of confidence bounds.


% \textbf{Queuing effects of changing allocations.} Lets skip this


% \textbf{Preemption, eviction and other mechanisms.}

\textbf{Limitations.}
Cilantro currently supports allocating only a single resource type. In our current implementation,
multiple resource types can be bundled into grouping units, such as VMs, which can then be scheduled
by Cilantro. However, such bundling is not always possible, especially when different jobs have
different resource requirements.
Extending Cilantro to handle multiple resource types is possible for welfare-based
fairness policies\cite{ghodsi2011dominant} and for optimizing end-to-end application performance.
However, learning and optimization can be challenging since the search space is now very large.
Another related limitation is that Cilantro cannot handle non-fungible resource types.
% 

Cilantro also does not support online learning versions of market-based resource allocation
policies in the multi-tenant setting~\citep{zahedi2018amdahl,lai2005tycoon,varian1973equity}.
% Market-based policies are performance-aware and strategy-proof.
These policies are computationally expensive and the application of OFU
is not straightforward. \rbcomment{Say that these are opportunities for future work.}



