\subsubsection{Baselines}
\label{sec:baselinesfixedclus}
\vspace{-1mm}

\newcommand{\bstitle}[1]{\textbf{#1.}}
\bstitle{Oracular policies}
We implement the three policies
in~\S\ref{sec:oracularpolicies} with oracular
access to the true performance mappings (obtained by exhaustively profiling workloads for at least 4 hours).
They are \oraclesw, \oracleew,  for maximizing social/egalitarian welfare
and the \oraclenjcs fairness policy.
% For \oraclesws and \oracleew, on each round,
% we maximize the welfare computed via the profiled performance curves using an evolutionary
% algorithm.
% Details of this evolutionary algorithm are given in the supplementary material.
% For \oraclenjc, we compute the demands using the profiled performance curves.

\bstitle{\cilantros policies}
We evaluate \cilantrosw, \cilantroew, and \cilantronjc, as described in
Sec.~\ref{sec:learningpolicies}.
% using \cilantro's online
% learning framework as described in Sec.~\ref{sec:learningpolicies}. 
% For \cilantrosws and \cilantroew, on each round,
% we maximize an upper confidence bound (UCB) on the welfare computed via the UCBs
% on the performance curves using an evolutionary algorithm.
% Since the UCBs are available in memory analytically this can be done efficiently.
% For \cilantronjc, we use the procedure described in~\citet{kandasamy20online}.

\bstitle{Other heuristics}
We implement four methods for fairness and
maximizing  welfare.
While not based directly off specific prior work, such methods are common in the
scheduling literature~\cite{crankshaw2017clipper,grandl2016altruistic}. \equalshare~simply
allocates an equal amount of resources to each job. \evoalgsw~and \evoalgew~are evolutionary
algorithms for social and egalitarian welfare; the same procedure used for Cilantro's welfare
policies, but now operating directly on the performance metrics.
\greedyew~starts by
allocating resources equally;
on each round, it evaluates job utilities in the previous round and
takes away one CPU each from the top half of the users who had high utility 
and allocates it to the bottom half.
% Then it chooses the $k$ jobs with the highest utility, takes away one resource each from these
% jobs, and then allocates it to the $k$ jobs with the lowest utility.
% In our evaluation, we used $k=3$; for smaller values of $k$, the changes were small
% and it resulted in slow convergence while for larger values the changes resulted in large
% fluctuations.

\bstitle{Baselines from prior work}
% To the best of our knowledge, there are no prior methods for the above criteria
% when the performance is unknown.
We adapt five feedback-driven methods from prior work to compare against Cilantro - \ernest~\cite{venkataraman2016ernest},
\quasar~\cite{delimitrou2014quasar},  \minerva~\cite{nathan2019end},
\parties~\cite{chen2019parties}~and \AIMD{}
(Multiplicative-Increase/Additive-Decrease)~\cite{chiu1989analysis}.

\begin{enumerate}[label=\arabic*)]

    \item \ernest~\cite{venkataraman2016ernest}:
    % Ernest uses a featurized linear model to estimate the time taken to run a job as a function of the
    % amount of resources allocated for the job and the load.
    % Equipped with this estimate, we approximate the resource demand for a job, i.e. the amount of
    % resources required, to satisfy a given target SLO for a given load.
    % On each round, we use the demand estimated in the above fashion as inputs to the max-min fairness
    % procedure to compute allocations for all jobs.
    % In our implementation, the Cilantro learners maintain this featurized linear model, which is
    % updated using non-negative least squares regression (as suggested by the authors) whenever there is
    % new data.
    Ernest uses a featurized linear model  to estimate the
    time taken to run a job.
    We use this estimate to approximate the resource demand to meet the job's SLO.
    On each round, we use the estimated demand as inputs to NJC to compute the allocations.
    % In our implementation, the Cilantro learners maintain this featurized linear model, which is
    % updated using non-negative least squares regression (as suggested by the authors) whenever there is
    % new data.
    \vspace{-0.05in}
    
    \item \quasar~\cite{delimitrou2014quasar}:
    Quasar uses collaborative filtering to estimate a job's resource demand, which we
    % We use this estimated deand as inputs to NJC to compute the allocations.
    use as inputs to NJC to compute the allocations.
    % The authors also describe procedures for vertical scaling and co-locating workloads based on
    % interference and heterogeneity.
    We do not incorporate mechanisms for vertical scaling and workload co-location described
    in~\cite{delimitrou2014quasar} to be consistent across all methods.
    % and since our experimental platform does not support extracting these metrics.
    \vspace{-0.05in}
    
    \item \minerva~\cite{nathan2019end}: 
    Minerva sets the allocation for
    job $j$ at each step to be proportional to $\allocj/\utilj$ where $\allocj$ and $\utilj$ are the
    allocation and utility at the previous round.
    % The stated goal of Minerva is to maximize the egalitarian welfare.
    % The authors also propose several video-streaming specific optimizations in addition to this core
    % algorithm which are not applicable in our setting.
    % The authors also describe an experiment design procedure for choosing an initial data set for
    % estimating the model; however, following this procedure for all jobs in our set up resulted in
    % infeasible allocations.
    % Hence, in the first 10 rounds of allocations, we chose the allocations randomly to initialise the
    % models for each job.
    
    \item \parties~\cite{chen2019parties}: 
    Parties upsizes the allocation for a job
    if it violates or is close to violating the SLO, downsizes the allocation if the job comfortably
    satisfies the SLO, and otherwise does nothing.
    If the SLOs of all jobs cannot be met, it evicts the job from the server.
    As eviction is not an option in our setting %as we we wish to fairly allocate resources,
    we use the Parties logic to compute the demands which are then fed to NJC to obtain the allocations.
    For upsizing, we increase the demand by 20 CPUs and for downsizing, we decrease it by 5.
    These parameters were tuned so that the policy did reasonably well on all three metrics.  \cameratext{In particular, we note that applying the \parties~notion of migration in our setting would imply moving the job to a different cluster or increasing the size of the cluster, both of which are beyond scope for this fixed cluster setting.}
    
    \item \AIMD{} (Multiplicative-Increase/Additive-Decrease)~\cite{chiu1989analysis}: 
    This is inspired by TCP congestion control.
    If a user's job violates the SLO, we increase its demand by $1.5\times$ the current allocation,
    and if it satisfies the SLO, we set the demand to be one minus the current allocation.
    We then invoke NJC to compute the allocation for the next round.
    These parameters were tuned so that the policy did reasonably well on all three metrics.
    \end{enumerate}


% In addition to the above three, we also considered the following prior work which could not be
% included in our evaluation.
% Google Autopilot's~\cite{rzadca2020autopilot} horizontal scaling procedure requires an application
% developer to specify a target CPU utilization and computes the resource demand based on the given
% target and the observed utilization.
% This requires an application developer to profile their workload to compute this target based on
% their SLO, which can be laborious.
% Additionally, our experimental platform does not support extracting CPU utilization metrics.
% Paragon~\cite{delimitrou2013paragon} and Allox~\cite{le2020allox} study the placement of jobs
% among heterogeneous resources and have no natural adaptation to our setting.
% Festive~\cite{jiang2012improving} describes a method for fair video streaming based on utilities,
% but their method cannot be adapted to data center resource allocation.





