\section{Experiment Addendum}
\romil{Move to paper}
\subsection{Workload description}

\textbf{Database querying:}
We use the TPC-DS \cite{tpc-ds} benchmark suite as the workload backed by replicated instances of sqlite3 database. 
%Each job's database is
%populated with the TPC-DS data generator with the scale factor parameter set to 100.
% The TPC-DS suite consists of 99 query templates
% out of which 27 were not compatible with the sqlite dialect and were discarded.
% Of the remaining workloads,
From the TPC-DS query set, we created two workloads (setting scale factor to 100): DB-0, which had queries that completed in under 100 ms and DB-1 which had queries that had a completion time between 100 and 300 ms.
When a query is requested, we randomly pick a relevant query and dispatch it
according to the trace. The performance metric of interest is  query latency.


\textbf{Prediction serving:}
In prediction serving~\cite{crankshaw2017clipper}, a job processes arriving queries
to output a prediction, usually obtained via a machine learning model.
In our set up, we use a random forest regressor as the model and the the news popularity
dataset~\cite{fernandes2015proactive} for training and test queries in a 50:50 split.
% Half of the dataset is used to train the model (before the experiment),
% while the remaining half (test set) is used to generate queries for the workload.
Queries are picked randomly from the test set and issued in batches of 4.
The metric of interest is the serving latency.
% When a query is 


\textbf{ML training:}
% Many real world machine learning deployments require that we continuously update the model
% from an input stream of data
% so as to account for changes in the data distribution~\cite{xiao2018gandiva}.
% \kkcomment{A good citation here.}
We use CPUs to train a neural network with four hidden layers of size 64 each.
We train our model on the naval propulsion~\cite{coraddu2016machine} dataset using
stochastic gradient descent (SGD).
Each task in this workload consists of training a batch of 16 points for 100 iterations. The performance metric of interest here is the batch throughput.
% Tasks are created from a 


\subsection{Environment details}

% \textbf{Resource-performance profiles.}  Resource-performance mappings for informing the oracle baselines in \S\ref{sec:fixedclus} were obtained through offline profiling of all workloads. These profiles are visualized in Figure \ref{fig:profiling}. 

% \insertFigProfiling

\textbf{Workload traces.} As described in \S\ref{sec:fixedclus}, we use traces collected from twitter to generate traffic patterns for our workloads. The query arrival rate of this trace is visualized in Figure \ref{fig:twitter_trace}.
\insertFigTwitterTrace

\textbf{Multi-tenant cluster jobs setup.} For the multi-tenant cluster resource sharing evaluation, we setup 20 jobs with different workloads and SLOs as described in in \S\ref{sec:fixedclus}. Table \ref{tab:expjobsetup} details the exact SLO and utility function for each job.  The utility function for each job is either of \incmtt{linear}, which directly maps performance to utility (Figure \ref{fig:utilityillus}(a)), \incmtt{sqrt}, which performs a sublinear mapping of performance to utility (Figure \ref{fig:utilityillus}(b)), or \incmtt{quadratic}, which performs a superlinear mapping of performance to utility (Figure \ref{fig:utilityillus}(c)).
\insertExpSetupTable

% \textbf{Multi-tenant cluster evaluation results.} Table \ref{tab:metrics} presents the detailed results of the multi-tenant cluster resource sharing evaluation in \S\ref{sec:fixedclus}. This table adds a  metric which measures the useful resource usage.
% \begin{align}
% \text{Useful resource usage}
% = \sum\nolimits_{j=1}^m \min(\allocj, d_j)
% \label{eqn:effresusage}
% \end{align}
% Here, the  $d_j$ is user $j$'s resource demand.
% % clipped (see Fig.~\ref{fig:utilityillus}).
% This demand-based metric,
% measures how much \emph{useful} work is being done by the cluster as allocations beyond the
% demand do not increase a user's utility (see Fig.~\ref{fig:utilityillus}).

% \insertTableMetrics

\textbf{TPC-DS Query Binning.} The queries used for the db serving workload in \S\ref{sec:fixedclus} were selected from the TPC-DS benchmark suite. The TPC-DS suite consists of 99 query templates out of which 27 were not compatible with the sqlite dialect and were discarded. The remainder were binned according to their mean latency when measured on a AWS m5.2xlarge instance. The chosen query types and their ids are listed in Table \ref{tab:querybinmap}
\insertTableQueryBins


\subsection{Baselines from prior work}
Here we describe the specific implementation of prior work baselines used in Section \ref{sec:experiments}.
\begin{enumerate}[label=\arabic*)]

\item \ernest~\cite{venkataraman2016ernest}:
% Ernest uses a featurized linear model to estimate the time taken to run a job as a function of the
% amount of resources allocated for the job and the load.
% Equipped with this estimate, we approximate the resource demand for a job, i.e. the amount of
% resources required, to satisfy a given target SLO for a given load.
% On each round, we use the demand estimated in the above fashion as inputs to the max-min fairness
% procedure to compute allocations for all jobs.
% In our implementation, the Cilantro learners maintain this featurized linear model, which is
% updated using non-negative least squares regression (as suggested by the authors) whenever there is
% new data.
Ernest uses a featurized linear model  to estimate the
time taken to run a job.
We use this estimate to approximate the resource demand to meet the job's SLO.
On each round, we use the estimated demand as inputs to NJC to compute the allocations.
% In our implementation, the Cilantro learners maintain this featurized linear model, which is
% updated using non-negative least squares regression (as suggested by the authors) whenever there is
% new data.
\vspace{-0.05in}

\item \quasar~\cite{delimitrou2014quasar}:
Quasar uses collaborative filtering to estimate a job's resource demand, which we
% We use this estimated deand as inputs to NJC to compute the allocations.
use as inputs to NJC to compute the allocations.
% The authors also describe procedures for vertical scaling and co-locating workloads based on
% interference and heterogeneity.
We do not incorporate mechanisms for vertical scaling and workload co-location described
in~\cite{delimitrou2014quasar} to be consistent across all methods.
% and since our experimental platform does not support extracting these metrics.
\vspace{-0.05in}

\item \minerva~\cite{nathan2019end}: 
Minerva sets the allocation for
job $j$ at each step to be proportional to $\allocj/\utilj$ where $\allocj$ and $\utilj$ are the
allocation and utility at the previous round.
% The stated goal of Minerva is to maximize the egalitarian welfare.
% The authors also propose several video-streaming specific optimizations in addition to this core
% algorithm which are not applicable in our setting.
% The authors also describe an experiment design procedure for choosing an initial data set for
% estimating the model; however, following this procedure for all jobs in our set up resulted in
% infeasible allocations.
% Hence, in the first 10 rounds of allocations, we chose the allocations randomly to initialise the
% models for each job.

\item \parties~\cite{chen2019parties}: 
Parties upsizes the allocation for a job
if it violates or is close to violating the SLO, downsizes the allocation if the job comfortably
satisfies the SLO, and otherwise does nothing.
If the SLOs of all jobs cannot be met, it evicts the job from the server.
As eviction is not an option in our setting %as we we wish to fairly allocate resources,
we use the Parties logic to compute the demands which are then fed to NJC to obtain the allocations.
For upsizing, we increase the demand by 20 CPUs and for downsizing, we decrease it by 5.
These parameters were tuned so that the policy did reasonably well on all three metrics.

\item \AIMD{} (Multiplicative-Increase/Additive-Decrease)~\cite{chiu1989analysis}: 
This is inspired by TCP congestion control.
If a user's job violates the SLO, we increase its demand by $1.5\times$ the current allocation,
and if it satisfies the SLO, we set the demand to be one minus the current allocation.
We then invoke NJC to compute the allocation for the next round.
These parameters were tuned so that the policy did reasonably well on all three metrics.
\end{enumerate}




\subsection{Evolutionary Algorithm}
We describe the evolutionary algorithm used in all of our experiments,
i.e to optimize the profiled information for the oracular welfare polices, to optimize the upper
confidence bounds for the learning policies in \S\ref{sec:learningpolicies} and\S\ref{sec:msal},
and the evolutionary algorithm baselines in \S\ref{sec:fixedclus} and\S\ref{sec:microservices}.
The input to the algorithm is a data source which the algorithm can query using an allocation and
obtain a feedback signal.
This data source can either be
a cheap analytically computable function
available in memory, as is the case for the oracles and learning polices,
or an expensive experiment, as is the case when used as a baseline to directly optimize for
performance.
The algorithm maintains a hash table mapping allocations to mean observed signal values.
When it receives feedback for an allocation, it updates the mean value if the allocation has already
been tried, or it creates a new entry and stores the feedback.

Our evolutionary algorithm proceeds as follows.
In has an initialization phase of 10 rounds.
In the first 2 rounds, it always queries a resource-fair allocation.
In the remaining  8 rounds, it queries a random allocation $\alloc$ such that
$\sum_{j=1}^n\allocj=R$.
On each subsequent round, it chooses a random allocation in the above manner with probability 0.1.
With probability 0.9, it samples one of the existing allocations in the hash table based on the
mean feedback value, performs a mutation operation, and queries the new allocation obtained
via the mutation.
We now to describe these two steps.
\begin{itemize}
\item \emph{Sampling:} Let $\{(\alloci, y_i\}_i$ be the (allocation, mean feedback) pairs in the
hash table.
Let $m, s$ denote the man and standard deviation of the $\{y_i\}$  values.
We sample $\alloci$ with probability proportional to $\exp\big((y_i-m)/s\big)$.
\item \emph{Mutation:}
The mutation operation is composed of a sequence of steps to modify a given allocation $a$.
At each step, we randomly sample one job $j$ which has an allocation of at least $2$ CPUs;
we then sample any other job $k\neq j$; we then decrease $j$'s allocation by $1$ and increase
$k$'s allocation by $1$.
The number of steps is chosen uniformly at random between 1 and 20.
\end{itemize}



\subsection{Other experimental details}

\textbf{Synthetic environment for robustness microbenchmark:}
For the microbenchmark in Fig.~\ref{fig:microbenchmarks}(left), we use 5 users whose load is
obtained
by the same twitter trace from the experiments, and whose synthetic performance function is given by
$p_j(a, \ell) = 1/(1+e^{-(a/\ell - b_j)})$, where $a$ is the allocation and $\ell$ is the load.
For the 5 users, we set $b_j\in \{0.1, 0.3, 0.5, 0.7, 0.9\}$.
We set the SLO to be 0.95 for all users (note that $0\leq p_j\leq 1$.
As the stochastic observation, we sample a Gaussian with standard deviation 0.2.

